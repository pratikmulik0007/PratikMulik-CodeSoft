{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654eccc9-a78d-42d5-806c-6f70f36f32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ff31db-e929-48a0-b40f-55665b75cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 : Import necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error, r2_score,accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Step 2 : Load the Dataset\n",
    "file_path = r\"C:\\Users\\pm045\\Desktop\\Codesoft\\IMDb Movies India.csv\"\n",
    "df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "df.head()\n",
    "\n",
    "#Step 3 : Data Exploration and Preprocessing\n",
    "#checking for missing values\n",
    "x = df.isnull().sum()\n",
    "print(x)\n",
    "\n",
    "#handling the missing values\n",
    "\n",
    "#Name --> no missing values\n",
    "#Step 3.1 : Year --> 528 missing values --> fill with most common year (median)\n",
    "#obstacle --> some values are written as strings instead od integer\n",
    "df['Year'] = df['Year'].astype(str) #first convert Year column to string\n",
    "df['Year'] = df['Year'].str.extract(r'(\\d+)') #extract digits\n",
    "df['Year'] = pd.to_numeric(df['Year'], errors='coerce') # Convert to numeric, coercing errors to NaN\n",
    "df[\"Year\"] = df[\"Year\"].fillna(df[\"Year\"].median())\n",
    "\n",
    "#Step 3.2 : Duration --> 8269 missing values --> fill with most common value of duration i.e.median\n",
    "#obstacle --> some values are like \"30 min\",etc i.e. in string format\n",
    "df['Duration'] = df['Duration'].str.replace(' min', '', regex=False)  # Remove \" min\" text\n",
    "df['Duration'] = pd.to_numeric(df['Duration'], errors='coerce')  # Convert to numeric, coercing errors to NaN\n",
    "df[\"Duration\"] = df[\"Duration\"].fillna(df[\"Duration\"].median())\n",
    "\n",
    "#Step 3.3 : Genre --> 1877 missing values --> fill with most frequently genre i.e.mode\n",
    "df[\"Genre\"] = df[\"Genre\"].fillna(df[\"Genre\"].mode()[0])\n",
    "\n",
    "#Step 3.4 : Rating --> 7590 missing values --> fill with median rating i.e.median\n",
    "df[\"Rating\"] = df[\"Rating\"].fillna(df[\"Rating\"].median())\n",
    "\n",
    "#Step 3.5 : Votes --> 7589 missing values --> fill with median number of votes i.e.median\n",
    "#obstacle --> some values are written as strings instead of integer like nana '8',etc\n",
    "df['Votes'] = df['Votes'].astype(str) #first convert Votes column to string\n",
    "df['Votes'] = df['Votes'].str.extract(r'(\\d+)') #extract digits\n",
    "df['Votes'] = pd.to_numeric(df['Votes'], errors='coerce') # Convert to numeric, coercing errors to NaN\n",
    "df[\"Votes\"] = df[\"Votes\"].fillna(df[\"Votes\"].median())\n",
    "\n",
    "#Step 3.6 : Director --> 525 missing values --> fill with \"unknown\"\n",
    "df[\"Director\"] = df[\"Director\"].fillna(\"unknown\")\n",
    "\n",
    "#Step 3.7 : Actor 1, Actor 2, Actor 3 --> 1617, 2384, 3144 missing values --> fill with \"unknown\"\n",
    "df[\"Actor 1\"] = df[\"Actor 1\"].fillna(\"unknown\")\n",
    "df[\"Actor 2\"] = df[\"Actor 2\"].fillna(\"unknown\")\n",
    "df[\"Actor 3\"] = df[\"Actor 3\"].fillna(\"unknown\")\n",
    "\n",
    "print(\"Status of the dataset after handling the missing values\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#Step 4 : Split the data into into features(x) and target(y)\n",
    "#split the features into numerical and categorical features\n",
    "numerical_features = ['Year','Duration','Votes']\n",
    "categorical_features = ['Genre','Director','Actor 1','Actor 2','Actor 3']\n",
    "\n",
    "#define transformers for numerical and catagorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='median')), #impute missing value with median value\n",
    "    ('scaler',StandardScaler()) #Scale numeric values\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='constant',fill_value='unknown')),\n",
    "    ('onehot',OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "#Step 5 : Combine both transformer into a column transformer\n",
    "preprocessor = ColumnTransformer( \n",
    "    transformers = [\n",
    "        ('num',numerical_transformer, numerical_features),\n",
    "        ('cat',categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "#Step 6 : Spliting the data into training and testing sets (80% and 20%)\n",
    "df_clean = df.dropna(subset=['Rating'])\n",
    "\n",
    "# Split features (X) and target (y)\n",
    "X = df_clean.drop('Rating', axis=1)\n",
    "y = df_clean['Rating']\n",
    "\n",
    "# Verify that the number of rows in X and y match\n",
    "print(X.shape)  # Should match the number of rows in y\n",
    "print(y.shape)  # Should be the same as X\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessing',preprocessor),\n",
    "    ('regression', RandomForestRegressor(n_estimators=100,random_state = 42))\n",
    "])\n",
    "\n",
    "#Step 7 : Train the model\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#Step 8 : Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Step 9 : Evaluate the model\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "print(f\"Mean Absolute Error : {mae}\")\n",
    "print(f\"Mean Squared Error : {mse}\")\n",
    "print(f\"R^2 Score : {r2}\")\n",
    "\n",
    "#Evaluate the model based on it's accuracy score\n",
    "# Ensure y_test and y_pred are integers\n",
    "y_test = y_test.astype(int)\n",
    "y_pred = y_pred.astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(f\"Accuracy of Model : {accuracy*100} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723f14b4-1610-4990-8cdc-0576112d1414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
